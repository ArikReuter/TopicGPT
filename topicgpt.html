<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>topicgpt package &mdash; topicgpt 0.0.4 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=8c5712d9"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Welcome to topicgpt’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            topicgpt
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">topicgpt package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-topicgpt.Clustering">topicgpt.Clustering module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed"><code class="docutils literal notranslate"><span class="pre">Clustering_and_DimRed</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed.cluster_and_reduce"><code class="docutils literal notranslate"><span class="pre">Clustering_and_DimRed.cluster_and_reduce()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed.cluster_hdbscan"><code class="docutils literal notranslate"><span class="pre">Clustering_and_DimRed.cluster_hdbscan()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed.reduce_dimensions_umap"><code class="docutils literal notranslate"><span class="pre">Clustering_and_DimRed.reduce_dimensions_umap()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed.umap_diagnostics"><code class="docutils literal notranslate"><span class="pre">Clustering_and_DimRed.umap_diagnostics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed.visualize_clusters_dynamic"><code class="docutils literal notranslate"><span class="pre">Clustering_and_DimRed.visualize_clusters_dynamic()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed.visualize_clusters_static"><code class="docutils literal notranslate"><span class="pre">Clustering_and_DimRed.visualize_clusters_static()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-topicgpt.ExtractTopWords">topicgpt.ExtractTopWords module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_bow_representation"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.compute_bow_representation()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_centroid_similarity"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.compute_centroid_similarity()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_corpus_vocab"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.compute_corpus_vocab()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_embedding_similarity_centroids"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.compute_embedding_similarity_centroids()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_word_topic_mat"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.compute_word_topic_mat()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_word_topic_mat_old"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.compute_word_topic_mat_old()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_words_topics"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.compute_words_topics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.embed_vocab_openAI"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.embed_vocab_openAI()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.extract_centroid"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.extract_centroid()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.extract_centroids"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.extract_centroids()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.extract_topwords_centroid_similarity"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.extract_topwords_centroid_similarity()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.extract_topwords_tfidf"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.extract_topwords_tfidf()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.ExtractTopWords.ExtractTopWords.get_most_similar_docs"><code class="docutils literal notranslate"><span class="pre">ExtractTopWords.get_most_similar_docs()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-topicgpt.GetEmbeddingsOpenAI">topicgpt.GetEmbeddingsOpenAI module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI"><code class="docutils literal notranslate"><span class="pre">GetEmbeddingsOpenAI</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.compute_number_of_tokens"><code class="docutils literal notranslate"><span class="pre">GetEmbeddingsOpenAI.compute_number_of_tokens()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.convert_api_res_list"><code class="docutils literal notranslate"><span class="pre">GetEmbeddingsOpenAI.convert_api_res_list()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.get_embeddings"><code class="docutils literal notranslate"><span class="pre">GetEmbeddingsOpenAI.get_embeddings()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.get_embeddings_doc_split"><code class="docutils literal notranslate"><span class="pre">GetEmbeddingsOpenAI.get_embeddings_doc_split()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.make_api_call"><code class="docutils literal notranslate"><span class="pre">GetEmbeddingsOpenAI.make_api_call()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.num_tokens_from_string"><code class="docutils literal notranslate"><span class="pre">GetEmbeddingsOpenAI.num_tokens_from_string()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.split_doc"><code class="docutils literal notranslate"><span class="pre">GetEmbeddingsOpenAI.split_doc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.split_long_docs"><code class="docutils literal notranslate"><span class="pre">GetEmbeddingsOpenAI.split_long_docs()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-topicgpt.TopicGPT">topicgpt.TopicGPT module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicGPT.TopicGPT"><code class="docutils literal notranslate"><span class="pre">TopicGPT</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicGPT.TopicGPT.compute_embeddings"><code class="docutils literal notranslate"><span class="pre">TopicGPT.compute_embeddings()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicGPT.TopicGPT.describe_topics"><code class="docutils literal notranslate"><span class="pre">TopicGPT.describe_topics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicGPT.TopicGPT.extract_topics"><code class="docutils literal notranslate"><span class="pre">TopicGPT.extract_topics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicGPT.TopicGPT.fit"><code class="docutils literal notranslate"><span class="pre">TopicGPT.fit()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicGPT.TopicGPT.pprompt"><code class="docutils literal notranslate"><span class="pre">TopicGPT.pprompt()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicGPT.TopicGPT.print_topics"><code class="docutils literal notranslate"><span class="pre">TopicGPT.print_topics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicGPT.TopicGPT.prompt"><code class="docutils literal notranslate"><span class="pre">TopicGPT.prompt()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicGPT.TopicGPT.repr_topics"><code class="docutils literal notranslate"><span class="pre">TopicGPT.repr_topics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicGPT.TopicGPT.save_embeddings"><code class="docutils literal notranslate"><span class="pre">TopicGPT.save_embeddings()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicGPT.TopicGPT.visualize_clusters"><code class="docutils literal notranslate"><span class="pre">TopicGPT.visualize_clusters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-topicgpt.TopicPrompting">topicgpt.TopicPrompting module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting"><code class="docutils literal notranslate"><span class="pre">TopicPrompting</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.add_new_topic_keyword"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.add_new_topic_keyword()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.combine_topics"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.combine_topics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.delete_topic"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.delete_topic()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.general_prompt"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.general_prompt()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.get_topic_information"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.get_topic_information()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.get_topic_lis"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.get_topic_lis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.identify_topic_idx"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.identify_topic_idx()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.knn_search"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.knn_search()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.prompt_knn_search"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.prompt_knn_search()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.reindex_topic_lis"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.reindex_topic_lis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.reindex_topics"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.reindex_topics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.set_topic_lis"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.set_topic_lis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.show_topic_lis"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.show_topic_lis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.split_topic_hdbscan"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.split_topic_hdbscan()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.split_topic_keywords"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.split_topic_keywords()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.split_topic_kmeans"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.split_topic_kmeans()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.split_topic_new_assignments"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.split_topic_new_assignments()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting.split_topic_single_keyword"><code class="docutils literal notranslate"><span class="pre">TopicPrompting.split_topic_single_keyword()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-topicgpt.TopicRepresentation">topicgpt.TopicRepresentation module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic"><code class="docutils literal notranslate"><span class="pre">Topic</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic.set_topic_description"><code class="docutils literal notranslate"><span class="pre">Topic.set_topic_description()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic.set_topic_name"><code class="docutils literal notranslate"><span class="pre">Topic.set_topic_name()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic.to_dict"><code class="docutils literal notranslate"><span class="pre">Topic.to_dict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic.to_json"><code class="docutils literal notranslate"><span class="pre">Topic.to_json()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicRepresentation.describe_and_name_topics"><code class="docutils literal notranslate"><span class="pre">describe_and_name_topics()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicRepresentation.extract_and_describe_topic_cos_sim"><code class="docutils literal notranslate"><span class="pre">extract_and_describe_topic_cos_sim()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicRepresentation.extract_and_describe_topics"><code class="docutils literal notranslate"><span class="pre">extract_and_describe_topics()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicRepresentation.extract_describe_topics_labels_vocab"><code class="docutils literal notranslate"><span class="pre">extract_describe_topics_labels_vocab()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicRepresentation.extract_topic_cos_sim"><code class="docutils literal notranslate"><span class="pre">extract_topic_cos_sim()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicRepresentation.extract_topics"><code class="docutils literal notranslate"><span class="pre">extract_topics()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicRepresentation.extract_topics_labels_vocab"><code class="docutils literal notranslate"><span class="pre">extract_topics_labels_vocab()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicRepresentation.extract_topics_no_new_vocab_computation"><code class="docutils literal notranslate"><span class="pre">extract_topics_no_new_vocab_computation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicRepresentation.topic_lis_to_json"><code class="docutils literal notranslate"><span class="pre">topic_lis_to_json()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopicRepresentation.topic_to_json"><code class="docutils literal notranslate"><span class="pre">topic_to_json()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-topicgpt.TopwordEnhancement">topicgpt.TopwordEnhancement module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement"><code class="docutils literal notranslate"><span class="pre">TopwordEnhancement</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.count_tokens_api_message"><code class="docutils literal notranslate"><span class="pre">TopwordEnhancement.count_tokens_api_message()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_document_sampling_str"><code class="docutils literal notranslate"><span class="pre">TopwordEnhancement.describe_topic_document_sampling_str()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_documents_completion_object"><code class="docutils literal notranslate"><span class="pre">TopwordEnhancement.describe_topic_documents_completion_object()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_documents_sampling_completion_object"><code class="docutils literal notranslate"><span class="pre">TopwordEnhancement.describe_topic_documents_sampling_completion_object()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_topwords_completion_object"><code class="docutils literal notranslate"><span class="pre">TopwordEnhancement.describe_topic_topwords_completion_object()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_topwords_str"><code class="docutils literal notranslate"><span class="pre">TopwordEnhancement.describe_topic_topwords_str()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.generate_topic_name_str"><code class="docutils literal notranslate"><span class="pre">TopwordEnhancement.generate_topic_name_str()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.sample_identity"><code class="docutils literal notranslate"><span class="pre">TopwordEnhancement.sample_identity()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.sample_poisson"><code class="docutils literal notranslate"><span class="pre">TopwordEnhancement.sample_poisson()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.sample_uniform"><code class="docutils literal notranslate"><span class="pre">TopwordEnhancement.sample_uniform()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-topicgpt">Module contents</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">topicgpt</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">topicgpt package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/topicgpt.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="topicgpt-package">
<h1>topicgpt package<a class="headerlink" href="#topicgpt-package" title="Link to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-topicgpt.Clustering">
<span id="topicgpt-clustering-module"></span><h2>topicgpt.Clustering module<a class="headerlink" href="#module-topicgpt.Clustering" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="topicgpt.Clustering.Clustering_and_DimRed">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">topicgpt.Clustering.</span></span><span class="sig-name descname"><span class="pre">Clustering_and_DimRed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_dims_umap</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors_umap</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_dist_umap</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_umap</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cosine'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_cluster_size_hdbscan</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_hdbscan</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_selection_method_hdbscan</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'eom'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">number_clusters_hdbscan</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">UMAP_hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">HDBSCAN_hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.Clustering.Clustering_and_DimRed" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class to perform dimensionality reduction with UMAP followed by clustering with HDBSCAN.</p>
<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.Clustering.Clustering_and_DimRed.cluster_and_reduce">
<span class="sig-name descname"><span class="pre">cluster_and_reduce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">UMAP</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.Clustering.Clustering_and_DimRed.cluster_and_reduce" title="Link to this definition"></a></dt>
<dd><p>Cluster embeddings using HDBSCAN and reduce dimensions with UMAP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>embeddings</strong> (<em>np.ndarray</em>) – Embeddings to cluster and reduce.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple containing three items:</dt><dd><ul class="simple">
<li><p>reduced_embeddings (np.ndarray): Reduced embeddings.</p></li>
<li><p>cluster_labels (np.ndarray): Cluster labels.</p></li>
<li><p>umap_mapper (umap.UMAP): UMAP mapper for transforming new embeddings, especially embeddings of the vocabulary. (MAKE SURE TO NORMALIZE EMBEDDINGS AFTER USING THE MAPPER)</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.Clustering.Clustering_and_DimRed.cluster_hdbscan">
<span class="sig-name descname"><span class="pre">cluster_hdbscan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#topicgpt.Clustering.Clustering_and_DimRed.cluster_hdbscan" title="Link to this definition"></a></dt>
<dd><p>Cluster embeddings using HDBSCAN.</p>
<p>If self.number_clusters_hdbscan is not None, further clusters the data with AgglomerativeClustering to achieve a fixed number of clusters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>embeddings</strong> (<em>np.ndarray</em>) – Embeddings to cluster.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Cluster labels.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.Clustering.Clustering_and_DimRed.reduce_dimensions_umap">
<span class="sig-name descname"><span class="pre">reduce_dimensions_umap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">UMAP</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.Clustering.Clustering_and_DimRed.reduce_dimensions_umap" title="Link to this definition"></a></dt>
<dd><p>Reduces dimensions of embeddings using UMAP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>embeddings</strong> (<em>np.ndarray</em>) – Embeddings to reduce.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple containing two items:</dt><dd><ul class="simple">
<li><p>reduced_embeddings (np.ndarray): Reduced embeddings.</p></li>
<li><p>umap_mapper (umap.UMAP): UMAP mapper for transforming new embeddings, especially embeddings of the vocabulary. (MAKE SURE TO NORMALIZE EMBEDDINGS AFTER USING THE MAPPER)</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.Clustering.Clustering_and_DimRed.umap_diagnostics">
<span class="sig-name descname"><span class="pre">umap_diagnostics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hammer_edges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.Clustering.Clustering_and_DimRed.umap_diagnostics" title="Link to this definition"></a></dt>
<dd><p>Fit UMAP on the provided embeddings and generate diagnostic plots.</p>
<section id="params">
<h3>Params:<a class="headerlink" href="#params" title="Link to this heading"></a></h3>
<dl class="simple">
<dt>embeddings<span class="classifier">array-like</span></dt><dd><p>The high-dimensional data for UMAP to reduce and visualize.</p>
</dd>
</dl>
<p>hammer_edges : bool, default False. Is computationally expensive.</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.Clustering.Clustering_and_DimRed.visualize_clusters_dynamic">
<span class="sig-name descname"><span class="pre">visualize_clusters_dynamic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">texts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.Clustering.Clustering_and_DimRed.visualize_clusters_dynamic" title="Link to this definition"></a></dt>
<dd><p>Visualize clusters using Plotly and enable hovering over clusters to see the beginning of the texts of the documents.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embeddings</strong> (<em>np.ndarray</em>) – Embeddings for which to visualize clustering.</p></li>
<li><p><strong>labels</strong> (<em>np.ndarray</em>) – Cluster labels.</p></li>
<li><p><strong>texts</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – Texts of the documents.</p></li>
<li><p><strong>class_names</strong> (<em>list</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Names of the classes.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.Clustering.Clustering_and_DimRed.visualize_clusters_static">
<span class="sig-name descname"><span class="pre">visualize_clusters_static</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.Clustering.Clustering_and_DimRed.visualize_clusters_static" title="Link to this definition"></a></dt>
<dd><p>Reduce dimensionality with UMAP to two dimensions and plot the clusters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embeddings</strong> (<em>np.ndarray</em>) – Embeddings for which to plot clustering.</p></li>
<li><p><strong>labels</strong> (<em>np.ndarray</em>) – Cluster labels.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-topicgpt.ExtractTopWords">
<span id="topicgpt-extracttopwords-module"></span><h2>topicgpt.ExtractTopWords module<a class="headerlink" href="#module-topicgpt.ExtractTopWords" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">topicgpt.ExtractTopWords.</span></span><span class="sig-name descname"><span class="pre">ExtractTopWords</span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.compute_bow_representation">
<span class="sig-name descname"><span class="pre">compute_bow_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">document</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_bow_representation" title="Link to this definition"></a></dt>
<dd><p>Compute the bag-of-words representation of a document.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>document</strong> (<em>str</em>) – Document to compute the bag-of-words representation of.</p></li>
<li><p><strong>vocab</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of words in the corpus sorted alphabetically.</p></li>
<li><p><strong>vocab_set</strong> (<em>set</em><em>[</em><em>str</em><em>]</em>) – Set of words in the corpus sorted alphabetically.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Bag-of-words representation of the document.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.compute_centroid_similarity">
<span class="sig-name descname"><span class="pre">compute_centroid_similarity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">centroid_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_centroid_similarity" title="Link to this definition"></a></dt>
<dd><p>Compute the similarity of the document embeddings to the centroid of the cluster via cosine similarity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embeddings</strong> (<em>np.ndarray</em>) – Embeddings to cluster and reduce.</p></li>
<li><p><strong>centroid_dict</strong> (<em>dict</em>) – Dictionary of cluster labels and their centroids.</p></li>
<li><p><strong>cluster_label</strong> (<em>int</em>) – Cluster label for which to compute the similarity.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Cosine similarity of the document embeddings to the centroid of the cluster.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.compute_corpus_vocab">
<span class="sig-name descname"><span class="pre">compute_corpus_vocab</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_stopwords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_punction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_word_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_word_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_short_words</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_numbers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_doc_frequency</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_freq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_freq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_corpus_vocab" title="Link to this definition"></a></dt>
<dd><p>Compute the vocabulary of the corpus and perform preprocessing of the corpus.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents.</p></li>
<li><p><strong>remove_stopwords</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to remove stopwords.</p></li>
<li><p><strong>remove_punction</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to remove punctuation.</p></li>
<li><p><strong>min_word_length</strong> (<em>int</em><em>, </em><em>optional</em>) – Minimum word length to retain.</p></li>
<li><p><strong>max_word_length</strong> (<em>int</em><em>, </em><em>optional</em>) – Maximum word length to retain.</p></li>
<li><p><strong>remove_short_words</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to remove short words.</p></li>
<li><p><strong>remove_numbers</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to remove numbers.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to print progress and describe what is happening.</p></li>
<li><p><strong>min_doc_frequency</strong> (<em>int</em><em>, </em><em>optional</em>) – Minimum number of documents a word should appear in to be considered in the vocabulary.</p></li>
<li><p><strong>min_freq</strong> (<em>float</em><em>, </em><em>optional</em>) – Minimum frequency percentile of words to be considered in the vocabulary.</p></li>
<li><p><strong>max_freq</strong> (<em>float</em><em>, </em><em>optional</em>) – Maximum frequency percentile of words to be considered in the vocabulary.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of words in the corpus sorted alphabetically.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.compute_embedding_similarity_centroids">
<span class="sig-name descname"><span class="pre">compute_embedding_similarity_centroids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_embedding_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">umap_mapper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">UMAP</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">centroid_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_vocab_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_centroid_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_embedding_similarity_centroids" title="Link to this definition"></a></dt>
<dd><p>Compute the cosine similarity of each word in the vocabulary to each centroid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of words in the corpus sorted alphabetically.</p></li>
<li><p><strong>vocab_embedding_dict</strong> (<em>dict</em>) – Dictionary of words and their embeddings.</p></li>
<li><p><strong>umap_mapper</strong> (<em>umap.UMAP</em>) – UMAP mapper to transform new embeddings in the same way as the document embeddings.</p></li>
<li><p><strong>centroid_dict</strong> (<em>dict</em>) – Dictionary of cluster labels and their centroids. -1 means outlier.</p></li>
<li><p><strong>reduce_vocab_embeddings</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to reduce the vocab embeddings with the UMAP mapper.</p></li>
<li><p><strong>reduce_centroid_embeddings</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to reduce the centroid embeddings with the UMAP mapper.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Cosine similarity of each word in the vocab to each centroid. Has shape (len(vocab), len(centroid_dict) - 1).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.compute_word_topic_mat">
<span class="sig-name descname"><span class="pre">compute_word_topic_mat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">consider_outliers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_word_topic_mat" title="Link to this definition"></a></dt>
<dd><p>Compute the word-topic matrix efficiently.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents.</p></li>
<li><p><strong>vocab</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of words in the corpus, sorted alphabetically.</p></li>
<li><p><strong>labels</strong> (<em>np.ndarray</em>) – Cluster labels. -1 indicates outliers.</p></li>
<li><p><strong>consider_outliers</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to consider outliers when computing the top words. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Word-topic matrix.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.compute_word_topic_mat_old">
<span class="sig-name descname"><span class="pre">compute_word_topic_mat_old</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">consider_outliers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_word_topic_mat_old" title="Link to this definition"></a></dt>
<dd><p>Compute the word-topic matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents.</p></li>
<li><p><strong>vocab</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of words in the corpus sorted alphabetically.</p></li>
<li><p><strong>labels</strong> (<em>np.ndarray</em>) – Cluster labels. -1 means outlier.</p></li>
<li><p><strong>consider_outliers</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to consider outliers when computing the top words. I.e. whether the labels contain -1 to indicate outliers.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Word-topic matrix.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.compute_words_topics">
<span class="sig-name descname"><span class="pre">compute_words_topics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.compute_words_topics" title="Link to this definition"></a></dt>
<dd><p>Compute the words per topic.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents.</p></li>
<li><p><strong>vocab</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of words in the corpus sorted alphabetically.</p></li>
<li><p><strong>labels</strong> (<em>np.ndarray</em>) – Cluster labels. -1 means outlier.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary of topics and their words.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.embed_vocab_openAI">
<span class="sig-name descname"><span class="pre">embed_vocab_openAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI" title="topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI"><span class="pre">GetEmbeddingsOpenAI</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.embed_vocab_openAI" title="Link to this definition"></a></dt>
<dd><p>Embed the vocabulary using the OpenAI embedding API.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>api_key</strong> (<em>str</em>) – OpenAI API key.</p></li>
<li><p><strong>vocab</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of words in the corpus sorted alphabetically.</p></li>
<li><p><strong>embedder</strong> (<a class="reference internal" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI" title="topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI"><em>GetEmbeddingsOpenAI</em></a><em>, </em><em>optional</em>) – Embedding object.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary of words and their embeddings.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, np.ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.extract_centroid">
<span class="sig-name descname"><span class="pre">extract_centroid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.extract_centroid" title="Link to this definition"></a></dt>
<dd><p>Extract the single centroid of a cluster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>embeddings</strong> (<em>np.ndarray</em>) – Embeddings to extract the centroid from.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The centroid of the cluster.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.extract_centroids">
<span class="sig-name descname"><span class="pre">extract_centroids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.extract_centroids" title="Link to this definition"></a></dt>
<dd><p>Extract centroids of clusters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embeddings</strong> (<em>np.ndarray</em>) – Embeddings to cluster and reduce.</p></li>
<li><p><strong>labels</strong> (<em>np.ndarray</em>) – Cluster labels. -1 means outlier.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary of cluster labels and their centroids.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.extract_topwords_centroid_similarity">
<span class="sig-name descname"><span class="pre">extract_topwords_centroid_similarity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">word_topic_mat:</span> <span class="pre">~numpy.ndarray,</span> <span class="pre">vocab:</span> <span class="pre">list[str],</span> <span class="pre">vocab_embedding_dict:</span> <span class="pre">dict,</span> <span class="pre">centroid_dict:</span> <span class="pre">dict,</span> <span class="pre">umap_mapper:</span> <span class="pre">~umap.umap_.UMAP,</span> <span class="pre">top_n_words:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">10,</span> <span class="pre">reduce_vocab_embeddings:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True,</span> <span class="pre">reduce_centroid_embeddings:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">consider_outliers:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False)</span> <span class="pre">-&gt;</span> <span class="pre">(&lt;class</span> <span class="pre">'dict'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'numpy.ndarray'&gt;</span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.extract_topwords_centroid_similarity" title="Link to this definition"></a></dt>
<dd><p>Extract the top words for each cluster by computing the cosine similarity of the words that occur in the corpus to the centroid of the cluster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>word_topic_mat</strong> (<em>np.ndarray</em>) – Word-topic matrix.</p></li>
<li><p><strong>vocab</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of words in the corpus sorted alphabetically.</p></li>
<li><p><strong>vocab_embedding_dict</strong> (<em>dict</em>) – Dictionary of words and their embeddings.</p></li>
<li><p><strong>centroid_dict</strong> (<em>dict</em>) – Dictionary of cluster labels and their centroids. -1 means outlier.</p></li>
<li><p><strong>umap_mapper</strong> (<em>umap.UMAP</em>) – UMAP mapper to transform new embeddings in the same way as the document embeddings.</p></li>
<li><p><strong>top_n_words</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top words to extract per topic.</p></li>
<li><p><strong>reduce_vocab_embeddings</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to reduce the vocab embeddings with the UMAP mapper.</p></li>
<li><p><strong>reduce_centroid_embeddings</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to reduce the centroid embeddings with the UMAP mapper.</p></li>
<li><p><strong>consider_outliers</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to consider outliers when computing the top words. I.e., whether the labels contain -1 to indicate outliers.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary of topics and their top words.
np.ndarray: Cosine similarity of each word in the vocab to each centroid. Has shape (len(vocab), len(centroid_dict) - 1).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.extract_topwords_tfidf">
<span class="sig-name descname"><span class="pre">extract_topwords_tfidf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">word_topic_mat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_n_words</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.extract_topwords_tfidf" title="Link to this definition"></a></dt>
<dd><p>Extract the top words for each topic using a class-based tf-idf score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>word_topic_mat</strong> (<em>np.ndarray</em>) – Word-topic matrix.</p></li>
<li><p><strong>vocab</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of words in the corpus sorted alphabetically.</p></li>
<li><p><strong>labels</strong> (<em>np.ndarray</em>) – Cluster labels. -1 means outlier.</p></li>
<li><p><strong>top_n_words</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top words to extract per topic.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary of topics and their top words.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.ExtractTopWords.ExtractTopWords.get_most_similar_docs">
<span class="sig-name descname"><span class="pre">get_most_similar_docs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">centroid_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.ExtractTopWords.ExtractTopWords.get_most_similar_docs" title="Link to this definition"></a></dt>
<dd><p>Get the most similar documents to the centroid of a cluster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents.</p></li>
<li><p><strong>embeddings</strong> (<em>np.ndarray</em>) – Embeddings to cluster and reduce.</p></li>
<li><p><strong>labels</strong> (<em>np.ndarray</em>) – Cluster labels. -1 means outlier.</p></li>
<li><p><strong>centroid_dict</strong> (<em>dict</em>) – Dictionary of cluster labels and their centroids.</p></li>
<li><p><strong>cluster_label</strong> (<em>int</em>) – Cluster label for which to compute the similarity.</p></li>
<li><p><strong>top_n</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top documents to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of the most similar documents to the centroid of a cluster.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[str]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-topicgpt.GetEmbeddingsOpenAI">
<span id="topicgpt-getembeddingsopenai-module"></span><h2>topicgpt.GetEmbeddingsOpenAI module<a class="headerlink" href="#module-topicgpt.GetEmbeddingsOpenAI" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">topicgpt.GetEmbeddingsOpenAI.</span></span><span class="sig-name descname"><span class="pre">GetEmbeddingsOpenAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'text-embedding-ada-002'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8191</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This class allows to compute embeddings of text using the OpenAI API.</p>
<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.compute_number_of_tokens">
<span class="sig-name descname"><span class="pre">compute_number_of_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.compute_number_of_tokens" title="Link to this definition"></a></dt>
<dd><p>Computes the total number of tokens needed to embed the corpus.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of strings to embed, where each element in the list is a document.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Total number of tokens needed to embed the corpus.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.convert_api_res_list">
<span class="sig-name descname"><span class="pre">convert_api_res_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_res_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.convert_api_res_list" title="Link to this definition"></a></dt>
<dd><p>Converts the api_res list into a dictionary containing the embeddings as a matrix and the corpus as a list of strings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>self</strong> – The instance of the class.</p></li>
<li><p><strong>api_res_list</strong> (<em>list</em><em>[</em><em>dict</em><em>]</em>) – List of dictionaries, where each dictionary contains the embedding of the document, the text of the document, and a list of errors that occurred during the embedding process.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary containing the embeddings as a matrix and the corpus as a list of strings.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.get_embeddings">
<span class="sig-name descname"><span class="pre">get_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.get_embeddings" title="Link to this definition"></a></dt>
<dd><p>Computes the embeddings of a corpus.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>self</strong> – The instance of the class.</p></li>
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of strings to embed, where each element in the list is a document.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary containing the embeddings as a matrix and the corpus as a list of strings.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.get_embeddings_doc_split">
<span class="sig-name descname"><span class="pre">get_embeddings_doc_split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_tries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.get_embeddings_doc_split" title="Link to this definition"></a></dt>
<dd><p>Computes the embeddings of a corpus for split documents.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>self</strong> – The instance of the class.</p></li>
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>list</em><em>[</em><em>str</em><em>]</em><em>]</em>) – List of strings to embed, where each element is a document represented by a list of its chunks.</p></li>
<li><p><strong>n_tries</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of tries to make an API call (default is 3).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of dictionaries, where each dictionary contains the embedding of the document, the text of the document, and a list of errors that occurred during the embedding process.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[dict]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.make_api_call">
<span class="sig-name descname"><span class="pre">make_api_call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.make_api_call" title="Link to this definition"></a></dt>
<dd><p>Makes an API call to the OpenAI API to embed a text string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>self</strong> – The instance of the class.</p></li>
<li><p><strong>text</strong> (<em>str</em>) – The string to embed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The response from the API.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>API response</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.num_tokens_from_string">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_tokens_from_string</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.num_tokens_from_string" title="Link to this definition"></a></dt>
<dd><p>Returns the number of tokens in a text string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>string</strong> (<em>str</em>) – Text string to compute the number of tokens.</p></li>
<li><p><strong>encoding</strong> – A function to encode the string into tokens.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Number of tokens in the text string.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.split_doc">
<span class="sig-name descname"><span class="pre">split_doc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.split_doc" title="Link to this definition"></a></dt>
<dd><p>Splits a single document that is longer than the maximum number of tokens into a list of smaller documents.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>self</strong> – The instance of the class.</p></li>
<li><p><strong>text</strong> (<em>str</em>) – The string to be split.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of strings to embed, where each element in the list is a list of chunks comprising the document.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.split_long_docs">
<span class="sig-name descname"><span class="pre">split_long_docs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.GetEmbeddingsOpenAI.GetEmbeddingsOpenAI.split_long_docs" title="Link to this definition"></a></dt>
<dd><p>Splits all documents that are longer than the maximum number of tokens into a list of smaller documents.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>self</strong> – The instance of the class.</p></li>
<li><p><strong>text</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of strings to embed, where each element in the list is a document.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of lists of strings to embed, where each element in the outer list is a list of chunks comprising the document.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[list[str]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-topicgpt.TopicGPT">
<span id="topicgpt-topicgpt-module"></span><h2>topicgpt.TopicGPT module<a class="headerlink" href="#module-topicgpt.TopicGPT" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="topicgpt.TopicGPT.TopicGPT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">topicgpt.TopicGPT.</span></span><span class="sig-name descname"><span class="pre">TopicGPT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">openai_api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_prompting_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gpt-3.5-turbo-16k'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_number_of_tokens</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16384</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">corpus_instruction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'text-embedding-ada-002'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_number_of_tokens_embedding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8191</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_saved_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clusterer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed" title="topicgpt.Clustering.Clustering_and_DimRed"><span class="pre">Clustering_and_DimRed</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords_description</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topword_extraction_methods</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">['tfidf',</span> <span class="pre">'cosine_similarity']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_vocab_hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enhancer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement" title="topicgpt.TopwordEnhancement.TopwordEnhancement"><span class="pre">TopwordEnhancement</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topic_prompting</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.TopicPrompting.TopicPrompting" title="topicgpt.TopicPrompting.TopicPrompting"><span class="pre">TopicPrompting</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicGPT.TopicGPT" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This is the main class for doing topic modelling with TopicGPT.</p>
<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicGPT.TopicGPT.compute_embeddings">
<span class="sig-name descname"><span class="pre">compute_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">corpus:</span> <span class="pre">list[str])</span> <span class="pre">-&gt;</span> <span class="pre">(&lt;class</span> <span class="pre">'numpy.ndarray'&gt;,</span> <span class="pre">dict[str,</span> <span class="pre">numpy.ndarray]</span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicGPT.TopicGPT.compute_embeddings" title="Link to this definition"></a></dt>
<dd><p>Computes document and vocabulary embeddings for the given corpus.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of strings to embed, where each element is a document.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple containing two items:</dt><dd><ul class="simple">
<li><p>document_embeddings (np.ndarray): Document embeddings for the corpus, with shape (len(corpus), n_embedding_dimensions).</p></li>
<li><p>vocab_embeddings (dict[str, np.ndarray]): Vocabulary embeddings for the corpus, provided as a dictionary where keys are words and values are embeddings.</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicGPT.TopicGPT.describe_topics">
<span class="sig-name descname"><span class="pre">describe_topics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicGPT.TopicGPT.describe_topics" title="Link to this definition"></a></dt>
<dd><p>Names and describes the provided topics using the OpenAI API.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>topics</strong> (<em>list</em><em>[</em><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><em>Topic</em></a><em>]</em>) – List of Topic objects to be named and described.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of Topic objects with names and descriptions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicGPT.TopicGPT.extract_topics">
<span class="sig-name descname"><span class="pre">extract_topics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicGPT.TopicGPT.extract_topics" title="Link to this definition"></a></dt>
<dd><p>Extracts topics from the given corpus.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of strings to process, where each element represents a document.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of Topic objects representing the extracted topics.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicGPT.TopicGPT.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicGPT.TopicGPT.fit" title="Link to this definition"></a></dt>
<dd><p>Compute embeddings if necessary, extract topics, and describe them.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of strings to embed, where each element represents a document.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to print the progress and details of the process.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicGPT.TopicGPT.pprompt">
<span class="sig-name descname"><span class="pre">pprompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_function_result</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">object</span></span></span><a class="headerlink" href="#topicgpt.TopicGPT.TopicGPT.pprompt" title="Link to this definition"></a></dt>
<dd><p>Prompts the model with the given query and prints the answer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>str</em>) – The query to prompt the model with.</p></li>
<li><p><strong>return_function_result</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to return the result of the function call by the Language Model (LLM).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The result of the function call if return_function_result is True, otherwise None.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicGPT.TopicGPT.print_topics">
<span class="sig-name descname"><span class="pre">print_topics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicGPT.TopicGPT.print_topics" title="Link to this definition"></a></dt>
<dd><p>Prints a string explanation of the topics.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicGPT.TopicGPT.prompt">
<span class="sig-name descname"><span class="pre">prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query:</span> <span class="pre">str)</span> <span class="pre">-&gt;</span> <span class="pre">(&lt;class</span> <span class="pre">'str'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">&lt;class</span> <span class="pre">'object'&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicGPT.TopicGPT.prompt" title="Link to this definition"></a></dt>
<dd><p>Prompts the model with the given query.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>query</strong> (<em>str</em>) – The query to prompt the model with.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple containing two items:</dt><dd><ul class="simple">
<li><p>answer (str): The answer from the model.</p></li>
<li><p>function_result (object): The result of the function call.</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please refer to the TopicPrompting class for more details on available functions for prompting the model.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicGPT.TopicGPT.repr_topics">
<span class="sig-name descname"><span class="pre">repr_topics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#topicgpt.TopicGPT.TopicGPT.repr_topics" title="Link to this definition"></a></dt>
<dd><p>Returns a string explanation of the topics.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicGPT.TopicGPT.save_embeddings">
<span class="sig-name descname"><span class="pre">save_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SavedEmbeddings/embeddings.pkl'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#topicgpt.TopicGPT.TopicGPT.save_embeddings" title="Link to this definition"></a></dt>
<dd><p>Saves the document and vocabulary embeddings to a pickle file for later re-use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em><em>, </em><em>optional</em>) – The path to save the embeddings to. Defaults to embeddings_path.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicGPT.TopicGPT.visualize_clusters">
<span class="sig-name descname"><span class="pre">visualize_clusters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicGPT.TopicGPT.visualize_clusters" title="Link to this definition"></a></dt>
<dd><p>Visualizes the identified clusters representing the topics in a scatterplot.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-topicgpt.TopicPrompting">
<span id="topicgpt-topicprompting-module"></span><h2>topicgpt.TopicPrompting module<a class="headerlink" href="#module-topicgpt.TopicPrompting" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">topicgpt.TopicPrompting.</span></span><span class="sig-name descname"><span class="pre">TopicPrompting</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_lis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_prompting_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gpt-3.5-turbo-16k'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_context_length_promting</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_model_temperature_prompting</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_embedding_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'text-embedding-ada-002'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_context_length_embedding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8191</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">basic_model_instruction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">&quot;You</span> <span class="pre">are</span> <span class="pre">a</span> <span class="pre">helpful</span> <span class="pre">assistant.</span> <span class="pre">\nYou</span> <span class="pre">are</span> <span class="pre">excellent</span> <span class="pre">at</span> <span class="pre">inferring</span> <span class="pre">information</span> <span class="pre">about</span> <span class="pre">topics</span> <span class="pre">discovered</span> <span class="pre">via</span> <span class="pre">topic</span> <span class="pre">modelling</span> <span class="pre">using</span> <span class="pre">information</span> <span class="pre">retrieval.</span> <span class="pre">\nYou</span> <span class="pre">summarize</span> <span class="pre">information</span> <span class="pre">intelligently.</span> <span class="pre">\nYou</span> <span class="pre">use</span> <span class="pre">the</span> <span class="pre">functions</span> <span class="pre">you</span> <span class="pre">are</span> <span class="pre">provided</span> <span class="pre">with</span> <span class="pre">if</span> <span class="pre">applicable.\nYou</span> <span class="pre">make</span> <span class="pre">sure</span> <span class="pre">that</span> <span class="pre">everything</span> <span class="pre">you</span> <span class="pre">output</span> <span class="pre">is</span> <span class="pre">strictly</span> <span class="pre">based</span> <span class="pre">on</span> <span class="pre">the</span> <span class="pre">provided</span> <span class="pre">text.</span> <span class="pre">If</span> <span class="pre">you</span> <span class="pre">cite</span> <span class="pre">documents,</span> <span class="pre">give</span> <span class="pre">their</span> <span class="pre">indices.</span> <span class="pre">\nYou</span> <span class="pre">always</span> <span class="pre">explicitly</span> <span class="pre">say</span> <span class="pre">if</span> <span class="pre">you</span> <span class="pre">don't</span> <span class="pre">find</span> <span class="pre">any</span> <span class="pre">useful</span> <span class="pre">information!\nYou</span> <span class="pre">only</span> <span class="pre">say</span> <span class="pre">that</span> <span class="pre">something</span> <span class="pre">is</span> <span class="pre">contained</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">corpus</span> <span class="pre">if</span> <span class="pre">you</span> <span class="pre">are</span> <span class="pre">very</span> <span class="pre">sure</span> <span class="pre">about</span> <span class="pre">it!&quot;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">corpus_instruction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enhancer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement" title="topicgpt.TopwordEnhancement.TopwordEnhancement"><span class="pre">TopwordEnhancement</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This class allows to formulate prompts and queries against the identified topics to get more information about them</p>
<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.add_new_topic_keyword">
<span class="sig-name descname"><span class="pre">add_new_topic_keyword</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keyword</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rename_new_topic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.add_new_topic_keyword" title="Link to this definition"></a></dt>
<dd><p>Create a new topic based on a keyword and recompute topic topwords.</p>
<p>This method removes all documents belonging to other topics from them and adds them to the new topic. It computes new topwords using both the tf-idf and the cosine-similarity method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keyword</strong> (<em>str</em>) – Keyword to create the new topic from.</p></li>
<li><p><strong>inplace</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the topic is updated in place. Otherwise, a new list of topics is created and returned (default is False).</p></li>
<li><p><strong>rename_new_topic</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the new topic is renamed to the keyword (default is False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of new topics, including the newly created topic and the modified old ones.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of <a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.combine_topics">
<span class="sig-name descname"><span class="pre">combine_topics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_idx_lis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.combine_topics" title="Link to this definition"></a></dt>
<dd><p>Combines several topics into one topic.</p>
<p>This method combines the specified topics into a single topic. Note that no new topwords are computed in this step, and the topwords of the old topics are just combined. Additionally, only the cosine-similarity method for topwords extraction is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topic_idx_list</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – List of topic indices to combine.</p></li>
<li><p><strong>inplace</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the topics are combined in place. Otherwise, a new list of topics is created and returned (default is False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of new topics resulting from the combination.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of <a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.delete_topic">
<span class="sig-name descname"><span class="pre">delete_topic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.delete_topic" title="Link to this definition"></a></dt>
<dd><p>Deletes a topic with the given index from the list of topics and recomputes topwords and representations of the remaining topics.</p>
<p>This method assigns the documents of the deleted topic to the remaining topics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topic_idx</strong> (<em>int</em>) – Index of the topic to delete.</p></li>
<li><p><strong>inplace</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the topic is deleted in place. Otherwise, a new list of topics is created and returned (default is False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of new topics resulting from the deletion.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of <a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.general_prompt">
<span class="sig-name descname"><span class="pre">general_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">prompt:</span> <span class="pre">str,</span> <span class="pre">n_tries:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">2)</span> <span class="pre">-&gt;</span> <span class="pre">(list[str],</span> <span class="pre">&lt;class</span> <span class="pre">'object'&gt;</span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.general_prompt" title="Link to this definition"></a></dt>
<dd><p>Prompt the Language Model (LLM) with a general prompt and return the response. Allow the LLM to call any function defined in the class.</p>
<p>Use n_tries in case the LLM does not provide a valid response.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) – Prompt string.</p></li>
<li><p><strong>n_tries</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of tries to get a valid response from the LLM (default is 2).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Response messages from the LLM.
object: Response of the invoked function.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.get_topic_information">
<span class="sig-name descname"><span class="pre">get_topic_information</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_idx_lis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_number_topwords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">500</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.get_topic_information" title="Link to this definition"></a></dt>
<dd><p>Get detailed information on topics by their indices.</p>
<p>This function returns a dictionary where the keys are the topic indices, and the values are strings describing the topics. The description includes a maximum of max_number_topwords topwords.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topic_idx_list</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – List of topic indices to compare.</p></li>
<li><p><strong>max_number_topwords</strong> (<em>int</em><em>, </em><em>optional</em>) – Maximum number of topwords to include in the description of the topics (default is 500).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary with topic indices as keys and their descriptions as values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.get_topic_lis">
<span class="sig-name descname"><span class="pre">get_topic_lis</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.get_topic_lis" title="Link to this definition"></a></dt>
<dd><p>Returns the list of topics stored in the instance.</p>
<p>This method retrieves and returns the list of topics associated with the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The list of Topic objects.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[<a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.identify_topic_idx">
<span class="sig-name descname"><span class="pre">identify_topic_idx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_tries</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.identify_topic_idx" title="Link to this definition"></a></dt>
<dd><p>Identifies the index of the topic that the query is most likely about.</p>
<p>This method uses a Language Model (LLM) to determine which topic best fits the query description. If the LLM does not find any topic that fits the query, None is returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>str</em>) – Query string.</p></li>
<li><p><strong>n_tries</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of tries to get a valid response from the LLM (default is 3).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The index of the topic that the query is most likely about. If no suitable topic is found, None is returned.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.knn_search">
<span class="sig-name descname"><span class="pre">knn_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">doc_cutoff_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.knn_search" title="Link to this definition"></a></dt>
<dd><p>Finds the k nearest neighbors of the query in the given topic based on cosine similarity in the original embedding space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topic_index</strong> (<em>int</em>) – Index of the topic to search within.</p></li>
<li><p><strong>query</strong> (<em>str</em>) – Query string.</p></li>
<li><p><strong>k</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of neighbors to return (default is 20).</p></li>
<li><p><strong>doc_cutoff_threshold</strong> (<em>int</em><em>, </em><em>optional</em>) – Maximum number of tokens per document. Afterwards, the document is cut off (default is 1000).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple containing two lists -</dt><dd><ul class="simple">
<li><p>A list of top k documents (as strings).</p></li>
<li><p>A list of indices corresponding to the top k documents in the topic.</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.prompt_knn_search">
<span class="sig-name descname"><span class="pre">prompt_knn_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">llm_query:</span> <span class="pre">str,</span> <span class="pre">topic_index:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">n_tries:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">3)</span> <span class="pre">-&gt;</span> <span class="pre">(&lt;class</span> <span class="pre">'str'&gt;,</span> <span class="pre">tuple[list[str],</span> <span class="pre">list[int]]</span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.prompt_knn_search" title="Link to this definition"></a></dt>
<dd><p>Uses the Language Model (LLM) to answer the llm_query based on the documents belonging to the topic.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>llm_query</strong> (<em>str</em>) – Query string for the Language Model (LLM).</p></li>
<li><p><strong>topic_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Index of the topic object. If None, the topic is inferred from the query.</p></li>
<li><p><strong>n_tries</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of tries to get a valid response from the LLM (default is 3).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple containing two elements -</dt><dd><ul class="simple">
<li><p>A string representing the answer from the LLM.</p></li>
<li><dl class="simple">
<dt>A tuple containing two lists -</dt><dd><ul>
<li><p>A list of top k documents (as strings).</p></li>
<li><p>A list of indices corresponding to the top k documents in the topic.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.reindex_topic_lis">
<span class="sig-name descname"><span class="pre">reindex_topic_lis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.reindex_topic_lis" title="Link to this definition"></a></dt>
<dd><p>Reindexes the topics in the provided topic list to assign correct new indices.</p>
<p>This method updates the indices of topics within the given topic list to ensure they are correctly ordered.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>topic_list</strong> (<em>list</em><em>[</em><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><em>Topic</em></a><em>]</em>) – The list of Topic objects to reindex.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The reindexed list of Topic objects.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.reindex_topics">
<span class="sig-name descname"><span class="pre">reindex_topics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.reindex_topics" title="Link to this definition"></a></dt>
<dd><p>Reindexes the topics in self.topic_list to assign correct new indices.</p>
<p>This method updates the indices of topics within the instance’s topic list to ensure they are correctly ordered.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.set_topic_lis">
<span class="sig-name descname"><span class="pre">set_topic_lis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.set_topic_lis" title="Link to this definition"></a></dt>
<dd><p>Sets the list of topics for the instance.</p>
<p>This method updates the list of topics associated with the instance to the provided list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>topic_list</strong> (<em>list</em><em>[</em><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><em>Topic</em></a><em>]</em>) – The list of Topic objects to set.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.show_topic_lis">
<span class="sig-name descname"><span class="pre">show_topic_lis</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.show_topic_lis" title="Link to this definition"></a></dt>
<dd><p>Returns a string representation of the list of topics.</p>
<p>This method generates a human-readable string representation of the topics in the instance’s topic list.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A string containing the representation of the list of topics.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.split_topic_hdbscan">
<span class="sig-name descname"><span class="pre">split_topic_hdbscan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_cluster_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.split_topic_hdbscan" title="Link to this definition"></a></dt>
<dd><p>Splits an existing topic into several subtopics using HDBSCAN clustering on the document embeddings of the topic.</p>
<p>This method does not require specifying the number of clusters to split. Note that no new topwords are computed in this step, and the topwords of the old topic are just split among the new ones. Additionally, only the cosine-similarity method for topwords extraction is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topic_idx</strong> (<em>int</em>) – Index of the topic to split.</p></li>
<li><p><strong>min_cluster_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Minimum cluster size to split the topic into (default is 100).</p></li>
<li><p><strong>inplace</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the topic is split in place. Otherwise, a new list of topics is created and returned (default is False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of new topics resulting from the split.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of <a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.split_topic_keywords">
<span class="sig-name descname"><span class="pre">split_topic_keywords</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keywords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.split_topic_keywords" title="Link to this definition"></a></dt>
<dd><p>Splits the topic into subtopics according to the provided keywords.</p>
<p>This is achieved by computing the cosine similarity between the keywords and the documents in the topic. Note that no new topwords are computed in this step, and the topwords of the old topic are just split among the new ones. Additionally, only the cosine-similarity method for topwords extraction is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topic_idx</strong> (<em>int</em>) – Index of the topic to split.</p></li>
<li><p><strong>keywords</strong> (<em>str</em>) – Keywords to split the topic into. Needs to be a list of at least two keywords.</p></li>
<li><p><strong>inplace</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the topic is split in place. Otherwise, a new list of topics is created and returned (default is False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of new topics resulting from the split.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of <a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.split_topic_kmeans">
<span class="sig-name descname"><span class="pre">split_topic_kmeans</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_clusters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.split_topic_kmeans" title="Link to this definition"></a></dt>
<dd><p>Splits an existing topic into several subtopics using k-means clustering on the document embeddings of the topic.</p>
<p>Note that no new topwords are computed in this step, and the topwords of the old topic are just split among the new ones. Additionally, only the cosine-similarity method for topwords extraction is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topic_idx</strong> (<em>int</em>) – Index of the topic to split.</p></li>
<li><p><strong>n_clusters</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of clusters to split the topic into (default is 2).</p></li>
<li><p><strong>inplace</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the topic is split in place. Otherwise, a new list of topics is created and returned (default is False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of new topics resulting from the split.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of <a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.split_topic_new_assignments">
<span class="sig-name descname"><span class="pre">split_topic_new_assignments</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_topic_assignments</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.split_topic_new_assignments" title="Link to this definition"></a></dt>
<dd><p>Splits a topic into new topics based on new topic assignments.</p>
<p>Note that this method only computes topwords based on the cosine-similarity method because tf-idf topwords need expensive computation on the entire corpus.
The topwords of the old topic are also just split among the new ones. No new topwords are computed in this step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topic_idx</strong> (<em>int</em>) – Index of the topic to split.</p></li>
<li><p><strong>new_topic_assignments</strong> (<em>np.ndarray</em>) – New topic assignments for the documents in the topic.</p></li>
<li><p><strong>inplace</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the topic is split in place. Otherwise, a new list of topics is created and returned (default is False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of new topics resulting from the split.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of <a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicPrompting.TopicPrompting.split_topic_single_keyword">
<span class="sig-name descname"><span class="pre">split_topic_single_keyword</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keyword</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicPrompting.TopicPrompting.split_topic_single_keyword" title="Link to this definition"></a></dt>
<dd><p>Splits the topic with a single keyword.</p>
<p>This method splits the topic such that all documents closer to the original topic name stay in the old topic, while all documents closer to the keyword are moved to the new topic. Note that no new topwords are computed in this step, and the topwords of the old topic are just split among the new ones. Additionally, only the cosine-similarity method for topwords extraction is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topic_idx</strong> (<em>int</em>) – Index of the topic to split.</p></li>
<li><p><strong>keyword</strong> (<em>str</em>) – Keyword to split the topic into.</p></li>
<li><p><strong>inplace</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the topic is split in place. Otherwise, a new list of topics is created and returned (default is False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of new topics resulting from the split.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of <a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-topicgpt.TopicRepresentation">
<span id="topicgpt-topicrepresentation-module"></span><h2>topicgpt.TopicRepresentation module<a class="headerlink" href="#module-topicgpt.TopicRepresentation" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.Topic">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">topicgpt.TopicRepresentation.</span></span><span class="sig-name descname"><span class="pre">Topic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">documents</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">words</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">centroid_hd</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">centroid_ld</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings_hd</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings_ld</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embedding_similarity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">umap_mapper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">UMAP</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_words</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_word_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicRepresentation.Topic" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>class to represent a topic and all its attributes</p>
<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.Topic.set_topic_description">
<span class="sig-name descname"><span class="pre">set_topic_description</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicRepresentation.Topic.set_topic_description" title="Link to this definition"></a></dt>
<dd><p>add a text description to the topic
params:</p>
<blockquote>
<div><p>text: text description of the topic</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.Topic.set_topic_name">
<span class="sig-name descname"><span class="pre">set_topic_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopicRepresentation.Topic.set_topic_name" title="Link to this definition"></a></dt>
<dd><p>add a name to the topic
params:</p>
<blockquote>
<div><p>name: name of the topic</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.Topic.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.Topic.to_dict" title="Link to this definition"></a></dt>
<dd><p>return a dict representation of the topic</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.Topic.to_json">
<span class="sig-name descname"><span class="pre">to_json</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.Topic.to_json" title="Link to this definition"></a></dt>
<dd><p>return a json representation of the topic</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.describe_and_name_topics">
<span class="sig-prename descclassname"><span class="pre">topicgpt.TopicRepresentation.</span></span><span class="sig-name descname"><span class="pre">describe_and_name_topics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enhancer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement" title="topicgpt.TopwordEnhancement.TopwordEnhancement"><span class="pre">TopwordEnhancement</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">topword_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tfidf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_words</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.describe_and_name_topics" title="Link to this definition"></a></dt>
<dd><p>Describe and name the topics using the OpenAI API with the given enhancer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topics</strong> (<em>list</em><em>[</em><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><em>Topic</em></a><em>]</em>) – List of Topic objects.</p></li>
<li><p><strong>enhancer</strong> (<a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement" title="topicgpt.TopwordEnhancement.TopwordEnhancement"><em>TopwordEnhancement</em></a>) – Enhancer object to enhance the top-words and generate the description.</p></li>
<li><p><strong>topword_method</strong> (<em>str</em><em>, </em><em>optional</em>) – Method to use for top-word extraction. Can be “tfidf” or “cosine_similarity” (default is “tfidf”).</p></li>
<li><p><strong>n_words</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of topwords to extract for the description and the name (default is 500).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of Topic objects with the description and name added.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.extract_and_describe_topic_cos_sim">
<span class="sig-prename descclassname"><span class="pre">topicgpt.TopicRepresentation.</span></span><span class="sig-name descname"><span class="pre">extract_and_describe_topic_cos_sim</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">documents_topic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings_topic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">words_topic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">umap_mapper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">UMAP</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enhancer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement" title="topicgpt.TopwordEnhancement.TopwordEnhancement"><span class="pre">TopwordEnhancement</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords_description</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.extract_and_describe_topic_cos_sim" title="Link to this definition"></a></dt>
<dd><p>Create a Topic object from the given documents and embeddings by computing the centroid and the top-words.
Only use cosine-similarity for top-word extraction.
Describe and name the topic with the given enhancer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>documents_topic</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents in the topic.</p></li>
<li><p><strong>document_embeddings_topic</strong> (<em>np.ndarray</em>) – High-dimensional embeddings of the documents in the topic.</p></li>
<li><p><strong>words_topic</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of words in the topic.</p></li>
<li><p><strong>vocab_embeddings</strong> (<em>dict</em>) – Embeddings of the vocabulary.</p></li>
<li><p><strong>umap_mapper</strong> (<em>umap.UMAP</em>) – UMAP mapper object to map from high-dimensional space to low-dimensional space.</p></li>
<li><p><strong>enhancer</strong> (<a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement" title="topicgpt.TopwordEnhancement.TopwordEnhancement"><em>TopwordEnhancement</em></a>) – Enhancer object to enhance the top-words and generate the description.</p></li>
<li><p><strong>n_topwords</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top-words to extract from the topics (default is 2000).</p></li>
<li><p><strong>n_topwords_description</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top-words to use from the extracted topics for the description and the name (default is 500).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Topic object representing the extracted and described topic.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.extract_and_describe_topics">
<span class="sig-prename descclassname"><span class="pre">topicgpt.TopicRepresentation.</span></span><span class="sig-name descname"><span class="pre">extract_and_describe_topics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clusterer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed" title="topicgpt.Clustering.Clustering_and_DimRed"><span class="pre">Clustering_and_DimRed</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enhancer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement" title="topicgpt.TopwordEnhancement.TopwordEnhancement"><span class="pre">TopwordEnhancement</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords_description</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topword_extraction_methods</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">['tfidf',</span> <span class="pre">'cosine_similarity']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_vocab_hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topword_description_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cosine_similarity'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.extract_and_describe_topics" title="Link to this definition"></a></dt>
<dd><p>Extracts topics from the given corpus using the provided clusterer object on the document embeddings and describes/names them using the given enhancer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents.</p></li>
<li><p><strong>document_embeddings</strong> (<em>np.ndarray</em>) – Embeddings of the documents.</p></li>
<li><p><strong>clusterer</strong> (<a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed" title="topicgpt.Clustering.Clustering_and_DimRed"><em>Clustering_and_DimRed</em></a>) – Clustering and dimensionality reduction object to cluster the documents.</p></li>
<li><p><strong>vocab_embeddings</strong> (<em>np.ndarray</em>) – Embeddings of the vocabulary.</p></li>
<li><p><strong>enhancer</strong> (<a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement" title="topicgpt.TopwordEnhancement.TopwordEnhancement"><em>TopwordEnhancement</em></a>) – Enhancer object for enhancing top-words and generating descriptions/names for topics.</p></li>
<li><p><strong>n_topwords</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top-words to extract from the topics (default is 2000).</p></li>
<li><p><strong>n_topwords_description</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top-words to use from the extracted topics for description and naming (default is 500).</p></li>
<li><p><strong>topword_extraction_methods</strong> (<em>list</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – List of methods to extract top-words from the topics.
Can contain “tfidf” and “cosine_similarity” (default is [“tfidf”, “cosine_similarity”]).</p></li>
<li><p><strong>compute_vocab_hyperparams</strong> (<em>dict</em><em>, </em><em>optional</em>) – Hyperparameters for the top-word extraction methods.</p></li>
<li><p><strong>topword_description_method</strong> (<em>str</em><em>, </em><em>optional</em>) – Method to use for top-word extraction for description/naming.
Can be “tfidf” or “cosine_similarity” (default is “cosine_similarity”).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of Topic objects representing the extracted and described topics.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.extract_describe_topics_labels_vocab">
<span class="sig-prename descclassname"><span class="pre">topicgpt.TopicRepresentation.</span></span><span class="sig-name descname"><span class="pre">extract_describe_topics_labels_vocab</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings_hd</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings_ld</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">umap_mapper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">UMAP</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enhancer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement" title="topicgpt.TopwordEnhancement.TopwordEnhancement"><span class="pre">TopwordEnhancement</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords_description</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topword_extraction_methods</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">['tfidf',</span> <span class="pre">'cosine_similarity']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topword_description_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cosine_similarity'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.extract_describe_topics_labels_vocab" title="Link to this definition"></a></dt>
<dd><p>Extracts topics from the given corpus using the provided labels that indicate the topics (no -1 for outliers). Vocabulary is already computed.
Describe and name the topics with the given enhancer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents.</p></li>
<li><p><strong>document_embeddings_hd</strong> (<em>np.ndarray</em>) – Embeddings of the documents in high-dimensional space.</p></li>
<li><p><strong>document_embeddings_ld</strong> (<em>np.ndarray</em>) – Embeddings of the documents in low-dimensional space.</p></li>
<li><p><strong>labels</strong> (<em>np.ndarray</em>) – Labels indicating the topics.</p></li>
<li><p><strong>umap_mapper</strong> (<em>umap.UMAP</em>) – UMAP mapper object to map from high-dimensional space to low-dimensional space.</p></li>
<li><p><strong>vocab_embeddings</strong> (<em>np.ndarray</em>) – Embeddings of the vocabulary.</p></li>
<li><p><strong>enhancer</strong> (<a class="reference internal" href="#topicgpt.TopwordEnhancement.TopwordEnhancement" title="topicgpt.TopwordEnhancement.TopwordEnhancement"><em>TopwordEnhancement</em></a>) – Enhancer object to enhance the top-words and generate the description.</p></li>
<li><p><strong>vocab</strong> (<em>list</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Vocabulary of the corpus (default is None).</p></li>
<li><p><strong>n_topwords</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top-words to extract from the topics (default is 2000).</p></li>
<li><p><strong>n_topwords_description</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top-words to use from the extracted topics for the description and the name (default is 500).</p></li>
<li><p><strong>topword_extraction_methods</strong> (<em>list</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – List of methods to extract top-words from the topics.
Can contain “tfidf” and “cosine_similarity” (default is [“tfidf”, “cosine_similarity”]).</p></li>
<li><p><strong>topword_description_method</strong> (<em>str</em><em>, </em><em>optional</em>) – Method to use for top-word extraction. Can be “tfidf” or “cosine_similarity” (default is “cosine_similarity”).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of Topic objects representing the extracted topics.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.extract_topic_cos_sim">
<span class="sig-prename descclassname"><span class="pre">topicgpt.TopicRepresentation.</span></span><span class="sig-name descname"><span class="pre">extract_topic_cos_sim</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">documents_topic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings_topic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">words_topic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">umap_mapper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">UMAP</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2000</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.extract_topic_cos_sim" title="Link to this definition"></a></dt>
<dd><p>Create a Topic object from the given documents and embeddings by computing the centroid and the top-words.
Only uses cosine-similarity for top-word extraction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>documents_topic</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents in the topic.</p></li>
<li><p><strong>document_embeddings_topic</strong> (<em>np.ndarray</em>) – High-dimensional embeddings of the documents in the topic.</p></li>
<li><p><strong>words_topic</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of words in the topic.</p></li>
<li><p><strong>vocab_embeddings</strong> (<em>dict</em>) – Embeddings of the vocabulary.</p></li>
<li><p><strong>umap_mapper</strong> (<em>umap.UMAP</em>) – UMAP mapper object to map from high-dimensional space to low-dimensional space.</p></li>
<li><p><strong>n_topwords</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top-words to extract from the topics (default is 2000).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Topic object representing the extracted topic.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.extract_topics">
<span class="sig-prename descclassname"><span class="pre">topicgpt.TopicRepresentation.</span></span><span class="sig-name descname"><span class="pre">extract_topics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clusterer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed" title="topicgpt.Clustering.Clustering_and_DimRed"><span class="pre">Clustering_and_DimRed</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topword_extraction_methods</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">['tfidf',</span> <span class="pre">'cosine_similarity']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_vocab_hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.extract_topics" title="Link to this definition"></a></dt>
<dd><p>Extracts topics from the given corpus using the provided clusterer object on the document embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents.</p></li>
<li><p><strong>document_embeddings</strong> (<em>np.ndarray</em>) – Embeddings of the documents.</p></li>
<li><p><strong>clusterer</strong> (<a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed" title="topicgpt.Clustering.Clustering_and_DimRed"><em>Clustering_and_DimRed</em></a>) – Clustering and dimensionality reduction object to cluster the documents.</p></li>
<li><p><strong>vocab_embeddings</strong> (<em>np.ndarray</em>) – Embeddings of the vocabulary.</p></li>
<li><p><strong>n_topwords</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top-words to extract from the topics (default is 2000).</p></li>
<li><p><strong>topword_extraction_methods</strong> (<em>list</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – List of methods to extract top-words from the topics.
Can contain “tfidf” and “cosine_similarity” (default is [“tfidf”, “cosine_similarity”]).</p></li>
<li><p><strong>compute_vocab_hyperparams</strong> (<em>dict</em><em>, </em><em>optional</em>) – Hyperparameters for the top-word extraction methods.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of Topic objects representing the extracted topics.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.extract_topics_labels_vocab">
<span class="sig-prename descclassname"><span class="pre">topicgpt.TopicRepresentation.</span></span><span class="sig-name descname"><span class="pre">extract_topics_labels_vocab</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings_hd</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings_ld</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">umap_mapper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">UMAP</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topword_extraction_methods</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">['tfidf',</span> <span class="pre">'cosine_similarity']</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.extract_topics_labels_vocab" title="Link to this definition"></a></dt>
<dd><p>Extracts topics from the given corpus using the provided labels that indicate the topics (no -1 for outliers). Vocabulary is already computed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents.</p></li>
<li><p><strong>document_embeddings_hd</strong> (<em>np.ndarray</em>) – Embeddings of the documents in high-dimensional space.</p></li>
<li><p><strong>document_embeddings_ld</strong> (<em>np.ndarray</em>) – Embeddings of the documents in low-dimensional space.</p></li>
<li><p><strong>labels</strong> (<em>np.ndarray</em>) – Labels indicating the topics.</p></li>
<li><p><strong>umap_mapper</strong> (<em>umap.UMAP</em>) – UMAP mapper object to map from high-dimensional space to low-dimensional space.</p></li>
<li><p><strong>vocab_embeddings</strong> (<em>np.ndarray</em>) – Embeddings of the vocabulary.</p></li>
<li><p><strong>vocab</strong> (<em>list</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Vocabulary of the corpus (default is None).</p></li>
<li><p><strong>n_topwords</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top-words to extract from the topics (default is 2000).</p></li>
<li><p><strong>topword_extraction_methods</strong> (<em>list</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – List of methods to extract top-words from the topics.
Can contain “tfidf” and “cosine_similarity” (default is [“tfidf”, “cosine_similarity”]).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of Topic objects representing the extracted topics.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.extract_topics_no_new_vocab_computation">
<span class="sig-prename descclassname"><span class="pre">topicgpt.TopicRepresentation.</span></span><span class="sig-name descname"><span class="pre">extract_topics_no_new_vocab_computation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">corpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">document_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clusterer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed" title="topicgpt.Clustering.Clustering_and_DimRed"><span class="pre">Clustering_and_DimRed</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_topwords</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topword_extraction_methods</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">['tfidf',</span> <span class="pre">'cosine_similarity']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">consider_outliers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.extract_topics_no_new_vocab_computation" title="Link to this definition"></a></dt>
<dd><p>Extracts topics from the given corpus using the provided clusterer object on the document embeddings.
This version does not compute the vocabulary of the corpus and instead uses the provided vocabulary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>corpus</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents.</p></li>
<li><p><strong>vocab</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – Vocabulary of the corpus.</p></li>
<li><p><strong>document_embeddings</strong> (<em>np.ndarray</em>) – Embeddings of the documents.</p></li>
<li><p><strong>clusterer</strong> (<a class="reference internal" href="#topicgpt.Clustering.Clustering_and_DimRed" title="topicgpt.Clustering.Clustering_and_DimRed"><em>Clustering_and_DimRed</em></a>) – Clustering and dimensionality reduction object to cluster the documents.</p></li>
<li><p><strong>vocab_embeddings</strong> (<em>np.ndarray</em>) – Embeddings of the vocabulary.</p></li>
<li><p><strong>n_topwords</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of top-words to extract from the topics (default is 2000).</p></li>
<li><p><strong>topword_extraction_methods</strong> (<em>list</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – List of methods to extract top-words from the topics.
Can contain “tfidf” and “cosine_similarity” (default is [“tfidf”, “cosine_similarity”]).</p></li>
<li><p><strong>consider_outliers</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to consider outliers during topic extraction (default is False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of Topic objects representing the extracted topics.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic">Topic</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.topic_lis_to_json">
<span class="sig-prename descclassname"><span class="pre">topicgpt.TopicRepresentation.</span></span><span class="sig-name descname"><span class="pre">topic_lis_to_json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.topic_lis_to_json" title="Link to this definition"></a></dt>
<dd><p>Return a JSON representation of a list of topics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>topics</strong> (<em>list</em><em>[</em><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><em>Topic</em></a><em>]</em>) – The list of topic objects to convert to JSON.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A JSON string representing the list of topics.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="topicgpt.TopicRepresentation.topic_to_json">
<span class="sig-prename descclassname"><span class="pre">topicgpt.TopicRepresentation.</span></span><span class="sig-name descname"><span class="pre">topic_to_json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><span class="pre">Topic</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#topicgpt.TopicRepresentation.topic_to_json" title="Link to this definition"></a></dt>
<dd><p>Return a JSON representation of the topic.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>topic</strong> (<a class="reference internal" href="#topicgpt.TopicRepresentation.Topic" title="topicgpt.TopicRepresentation.Topic"><em>Topic</em></a>) – The topic object to convert to JSON.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A JSON string representing the topic.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-topicgpt.TopwordEnhancement">
<span id="topicgpt-topwordenhancement-module"></span><h2>topicgpt.TopwordEnhancement module<a class="headerlink" href="#module-topicgpt.TopwordEnhancement" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="topicgpt.TopwordEnhancement.TopwordEnhancement">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">topicgpt.TopwordEnhancement.</span></span><span class="sig-name descname"><span class="pre">TopwordEnhancement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">openai_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gpt-3.5-turbo'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_context_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_model_temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">basic_model_instruction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'You</span> <span class="pre">are</span> <span class="pre">a</span> <span class="pre">helpful</span> <span class="pre">assistant.</span> <span class="pre">You</span> <span class="pre">are</span> <span class="pre">excellent</span> <span class="pre">at</span> <span class="pre">inferring</span> <span class="pre">topics</span> <span class="pre">from</span> <span class="pre">top-words</span> <span class="pre">extracted</span> <span class="pre">via</span> <span class="pre">topic-modelling.</span> <span class="pre">You</span> <span class="pre">make</span> <span class="pre">sure</span> <span class="pre">that</span> <span class="pre">everything</span> <span class="pre">you</span> <span class="pre">output</span> <span class="pre">is</span> <span class="pre">strictly</span> <span class="pre">based</span> <span class="pre">on</span> <span class="pre">the</span> <span class="pre">provided</span> <span class="pre">text.'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">corpus_instruction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topicgpt.TopwordEnhancement.TopwordEnhancement" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopwordEnhancement.TopwordEnhancement.count_tokens_api_message">
<span class="sig-name descname"><span class="pre">count_tokens_api_message</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.count_tokens_api_message" title="Link to this definition"></a></dt>
<dd><p>Count the number of tokens in the API messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>list</em><em>[</em><em>dict</em><em>[</em><em>str</em><em>]</em><em>]</em>) – List of messages from the API.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Number of tokens in the messages.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_document_sampling_str">
<span class="sig-name descname"><span class="pre">describe_topic_document_sampling_str</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">documents:</span> <span class="pre">list[str],</span> <span class="pre">truncate_doc_thresh=100,</span> <span class="pre">n_documents:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">query_function:</span> <span class="pre">~typing.Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">TopwordEnhancement.&lt;lambda&gt;&gt;,</span> <span class="pre">sampling_strategy:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_document_sampling_str" title="Link to this definition"></a></dt>
<dd><p>Describe a topic based on a sample of its documents by using the openai model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>documents</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents ordered by similarity to the topic’s centroid.</p></li>
<li><p><strong>truncate_doc_thresh</strong> (<em>int</em><em>, </em><em>optional</em>) – Threshold for the number of words in a document. If a document exceeds this threshold, it is truncated. Defaults to 100.</p></li>
<li><p><strong>n_documents</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of documents to use for the query. If None, all documents are used. Defaults to None.</p></li>
<li><p><strong>query_function</strong> (<em>Callable</em><em>, </em><em>optional</em>) – Function to query the model. Defaults to a lambda function generating a query based on the provided documents.</p></li>
<li><p><strong>sampling_strategy</strong> (<em>Union</em><em>[</em><em>Callable</em><em>, </em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Strategy to sample the documents. If None, the first provided documents are used.
If it’s a string, it’s interpreted as a method of the class (e.g., “sample_uniform” is interpreted as self.sample_uniform). It can also be a custom sampling function. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A description of the topic by the model in the form of a string.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_documents_completion_object">
<span class="sig-name descname"><span class="pre">describe_topic_documents_completion_object</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">documents:</span> <span class="pre">list[str],</span> <span class="pre">truncate_doc_thresh=100,</span> <span class="pre">n_documents:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">query_function:</span> <span class="pre">~typing.Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">TopwordEnhancement.&lt;lambda&gt;&gt;</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ChatCompletion</span></span></span><a class="headerlink" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_documents_completion_object" title="Link to this definition"></a></dt>
<dd><p>Describe the given topic based on its documents using the OpenAI model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>documents</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents.</p></li>
<li><p><strong>truncate_doc_thresh</strong> (<em>int</em><em>, </em><em>optional</em>) – Threshold for the number of words in a document. If a document has more words than this threshold, it is pruned to this threshold.</p></li>
<li><p><strong>n_documents</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of documents to use for the query. If None, all documents are used.</p></li>
<li><p><strong>query_function</strong> (<em>Callable</em><em>, </em><em>optional</em>) – Function to query the model. The function should take a list of documents and return a string.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A description of the topics by the model in the form of an openai.ChatCompletion object.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>openai.ChatCompletion</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_documents_sampling_completion_object">
<span class="sig-name descname"><span class="pre">describe_topic_documents_sampling_completion_object</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">documents:</span> <span class="pre">list[str],</span> <span class="pre">truncate_doc_thresh=100,</span> <span class="pre">n_documents:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">query_function:</span> <span class="pre">~typing.Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">TopwordEnhancement.&lt;lambda&gt;&gt;,</span> <span class="pre">sampling_strategy:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ChatCompletion</span></span></span><a class="headerlink" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_documents_sampling_completion_object" title="Link to this definition"></a></dt>
<dd><p>Describe a topic based on a sample of its documents by using the openai model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>documents</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of documents ordered by similarity to the topic’s centroid.</p></li>
<li><p><strong>truncate_doc_thresh</strong> (<em>int</em><em>, </em><em>optional</em>) – Threshold for the number of words in a document. If a document exceeds this threshold, it is truncated. Defaults to 100.</p></li>
<li><p><strong>n_documents</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of documents to use for the query. If None, all documents are used. Defaults to None.</p></li>
<li><p><strong>query_function</strong> (<em>Callable</em><em>, </em><em>optional</em>) – Function to query the model. Defaults to a lambda function generating a query based on the provided documents.</p></li>
<li><p><strong>sampling_strategy</strong> (<em>Union</em><em>[</em><em>Callable</em><em>, </em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Strategy to sample the documents. If None, the first provided documents are used.
If it’s a string, it’s interpreted as a method of the class (e.g., “sample_uniform” is interpreted as self.sample_uniform). It can also be a custom sampling function. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A description of the topic by the model in the form of an openai.ChatCompletion object.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>openai.ChatCompletion</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_topwords_completion_object">
<span class="sig-name descname"><span class="pre">describe_topic_topwords_completion_object</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">topwords:</span> <span class="pre">list[str],</span> <span class="pre">n_words:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">query_function:</span> <span class="pre">~typing.Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">TopwordEnhancement.&lt;lambda&gt;&gt;</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ChatCompletion</span></span></span><a class="headerlink" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_topwords_completion_object" title="Link to this definition"></a></dt>
<dd><p>Describe the given topic based on its topwords using the OpenAI model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topwords</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of topwords.</p></li>
<li><p><strong>n_words</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of words to use for the query. If None, all words are used.</p></li>
<li><p><strong>query_function</strong> (<em>Callable</em><em>, </em><em>optional</em>) – Function to query the model. The function should take a list of topwords and return a string.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A description of the topics by the model in the form of an OpenAI ChatCompletion object.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>openai.ChatCompletion</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_topwords_str">
<span class="sig-name descname"><span class="pre">describe_topic_topwords_str</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">topwords:</span> <span class="pre">list[str],</span> <span class="pre">n_words:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">query_function:</span> <span class="pre">~typing.Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">TopwordEnhancement.&lt;lambda&gt;&gt;</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.describe_topic_topwords_str" title="Link to this definition"></a></dt>
<dd><p>Describe the given topic based on its topwords using the OpenAI model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topwords</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of topwords.</p></li>
<li><p><strong>n_words</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of words to use for the query. If None, all words are used.</p></li>
<li><p><strong>query_function</strong> (<em>Callable</em><em>, </em><em>optional</em>) – Function to query the model. The function should take a list of topwords and return a string.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A description of the topics by the model in the form of a string.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopwordEnhancement.TopwordEnhancement.generate_topic_name_str">
<span class="sig-name descname"><span class="pre">generate_topic_name_str</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">topwords:</span> <span class="pre">list[str],</span> <span class="pre">n_words:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">query_function:</span> <span class="pre">~typing.Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">TopwordEnhancement.&lt;lambda&gt;&gt;</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.generate_topic_name_str" title="Link to this definition"></a></dt>
<dd><p>Generate a topic name based on the given topwords using the OpenAI model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topwords</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of topwords.</p></li>
<li><p><strong>n_words</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of words to use for the query. If None, all words are used.</p></li>
<li><p><strong>query_function</strong> (<em>Callable</em><em>, </em><em>optional</em>) – Function to query the model. The function should take a list of topwords and return a string.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A topic name generated by the model in the form of a string.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopwordEnhancement.TopwordEnhancement.sample_identity">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_identity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_docs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.sample_identity" title="Link to this definition"></a></dt>
<dd><p>Generate an identity array of document indices without changing their order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>n_docs</strong> (<em>int</em>) – Number of documents.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An array containing document indices from 0 to (n_docs - 1).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopwordEnhancement.TopwordEnhancement.sample_poisson">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_poisson</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_docs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.sample_poisson" title="Link to this definition"></a></dt>
<dd><p>Randomly sample document indices according to a Poisson distribution, favoring documents from the beginning of the list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>n_docs</strong> (<em>int</em>) – Number of documents.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An array containing randomly permuted document indices, with more documents drawn from the beginning of the list.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topicgpt.TopwordEnhancement.TopwordEnhancement.sample_uniform">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_uniform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_docs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#topicgpt.TopwordEnhancement.TopwordEnhancement.sample_uniform" title="Link to this definition"></a></dt>
<dd><p>Randomly sample document indices without replacement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>n_docs</strong> (<em>int</em>) – Number of documents.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An array containing randomly permuted document indices from 0 to (n_docs - 1).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-topicgpt">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-topicgpt" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to topicgpt’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, ArikReuter.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>